version: '3.8'

services:
  # Redis service
  redis:
    image: redis:7-alpine
    container_name: lynx-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --requirepass lynx123456
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - lynx-network

  # MySQL service
  mysql:
    image: mysql:8.0
    container_name: lynx-mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: lynx123456
      MYSQL_DATABASE: lynx_test
      MYSQL_USER: lynx
      MYSQL_PASSWORD: lynx123456
    volumes:
      - mysql-data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - lynx-network

  # PostgreSQL service
  postgres:
    image: postgres:15-alpine
    container_name: lynx-postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: lynx
      POSTGRES_PASSWORD: lynx123456
      POSTGRES_DB: lynx_test
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lynx"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - lynx-network

  # Kafka service
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: lynx-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - lynx-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: lynx-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Elasticsearch service
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: lynx-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # MongoDB service
  mongodb:
    image: mongo:latest
    container_name: lynx-mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: lynx
      MONGO_INITDB_ROOT_PASSWORD: lynx123456
      MONGO_INITDB_DATABASE: lynx_test
    volumes:
      - mongo-data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - lynx-network

  # RabbitMQ service
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: lynx-rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: lynx
      RABBITMQ_DEFAULT_PASS: lynx123456
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    networks:
      - lynx-network

  # RocketMQ NameServer
  rocketmq-namesrv:
    image: apache/rocketmq:5.1.0
    container_name: lynx-rocketmq-namesrv
    ports:
      - "9876:9876"
    command: sh mqnamesrv
    environment:
      JAVA_OPT_EXT: "-Xms256m -Xmx256m"
    networks:
      - lynx-network

  # RocketMQ Broker
  rocketmq-broker:
    image: apache/rocketmq:5.1.0
    container_name: lynx-rocketmq-broker
    ports:
      - "10911:10911"
      - "10909:10909"
    command: sh mqbroker -n rocketmq-namesrv:9876 -c /home/rocketmq/rocketmq-5.1.0/conf/broker.conf
    environment:
      JAVA_OPT_EXT: "-Xms256m -Xmx256m"
    depends_on:
      - rocketmq-namesrv
    networks:
      - lynx-network

  # Polaris service (service governance)
  polaris:
    image: polarismesh/polaris-standalone:latest
    container_name: lynx-polaris
    restart: unless-stopped
    ports:
      - "8081:8080"   # Console UI (changed to avoid conflict)
      - "8090:8090"   # HTTP API
      - "8091:8091"   # gRPC API
      - "8093:8093"   # Config center HTTP
      - "8761:8761"   # Eureka compatible
      - "8848:8848"   # Nacos compatible API
      - "9848:9848"   # Nacos gRPC compatible
      - "15010:15010" # xDS v3 (Envoy)
      - "9090:9090"   # Prometheus metrics
      - "9091:9091"   # Management interface
      - "8100:8100"   # Internal port (optional)
      - "8101:8101"   # Internal port (optional)
    volumes:
      - polaris-data:/data
    networks:
      - lynx-network

  # Nacos service (service registry and config center)
  # Using standalone mode with embedded Derby database (no MySQL required)
  nacos:
    image: nacos/nacos-server:v2.3.0
    container_name: lynx-nacos
    ports:
      - "8848:8848"   # Nacos server port
      - "9848:9848"   # Nacos gRPC port
      - "9847:9847"   # Nacos client gRPC request server
    environment:
      MODE: standalone
      NACOS_AUTH_ENABLE: false
      NACOS_AUTH_IDENTITY_KEY: serverIdentity
      NACOS_AUTH_IDENTITY_VALUE: security
      PREFER_HOST_MODE: hostname
    volumes:
      - nacos-data:/home/nacos/data
      - nacos-logs:/home/nacos/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8848/nacos/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # etcd service (config center)
  etcd:
    image: quay.io/coreos/etcd:v3.5.9
    container_name: lynx-etcd
    ports:
      - "2379:2379"   # Client port
      - "2380:2380"   # Peer port
    environment:
      ETCD_NAME: lynx-etcd
      ETCD_DATA_DIR: /etcd-data
      ETCD_LISTEN_CLIENT_URLS: http://0.0.0.0:2379
      ETCD_ADVERTISE_CLIENT_URLS: http://localhost:2379
      ETCD_LISTEN_PEER_URLS: http://0.0.0.0:2380
      ETCD_INITIAL_ADVERTISE_PEER_URLS: http://localhost:2380
      ETCD_INITIAL_CLUSTER: lynx-etcd=http://localhost:2380
      ETCD_INITIAL_CLUSTER_TOKEN: lynx-etcd-cluster
      ETCD_INITIAL_CLUSTER_STATE: new
    volumes:
      - etcd-data:/etcd-data
    healthcheck:
      test: ["CMD", "etcdctl", "--endpoints=http://localhost:2379", "endpoint", "health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Apache Pulsar service
  pulsar:
    image: apachepulsar/pulsar:latest
    container_name: lynx-pulsar
    ports:
      - "6650:6650"   # Pulsar broker port
      - "8082:8080"   # Pulsar HTTP port (changed to avoid conflict)
    command: bin/pulsar standalone
    environment:
      PULSAR_MEM: "-Xms512m -Xmx512m -XX:MaxDirectMemorySize=256m"
    volumes:
      - pulsar-data:/pulsar/data
    healthcheck:
      test: ["CMD", "bin/pulsar-admin", "brokers", "healthcheck"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # DTM (Distributed Transaction Manager)
  dtm:
    image: yedf/dtm:latest
    container_name: lynx-dtm
    ports:
      - "36789:36789"   # HTTP API port
      - "36790:36790"   # gRPC port
    environment:
      STORE_DRIVER: redis
      STORE_HOST: redis
      STORE_PORT: 6379
      STORE_PASSWORD: lynx123456
      STORE_DB: 0
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:36789/api/dtmsvr/ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Seata (Distributed Transaction Manager)
  seata-server:
    image: seataio/seata-server:1.8.0
    container_name: lynx-seata
    ports:
      - "8091:8091"   # Seata server port
    environment:
      SEATA_PORT: 8091
      STORE_MODE: file
      SEATA_CONFIG_NAME: file:/root/seata-config/registry
    volumes:
      - seata-data:/root/seata/sessionStore
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -z localhost 8091 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Sentinel Dashboard (traffic control)
  sentinel-dashboard:
    image: bladex/sentinel-dashboard:1.8.6
    container_name: lynx-sentinel
    ports:
      - "8719:8719"   # Sentinel dashboard port
    environment:
      JAVA_OPTS: "-Dserver.port=8719 -Dcsp.sentinel.dashboard.server=localhost:8719"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8719/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Microsoft SQL Server
  mssql:
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: lynx-mssql
    ports:
      - "1433:1433"
    environment:
      ACCEPT_EULA: "Y"
      MSSQL_SA_PASSWORD: "Lynx123456!"
      MSSQL_PID: "Developer"
    volumes:
      - mssql-data:/var/opt/mssql
    healthcheck:
      test: ["CMD-SHELL", "/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P 'Lynx123456!' -Q 'SELECT 1' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Apollo Config Service
  # Note: If image pull fails due to network issues (TLS handshake timeout), you can:
  # 1. Skip Apollo services: docker-compose up -d (without --profile apollo)
  # 2. Configure Docker registry mirror (see DOCKER_NETWORK_FIX.md)
  # 3. Manually pull images: docker pull apolloconfig/apollo-configservice:2.1.0
  # To start with Apollo: docker-compose --profile apollo up -d
  apollo-configservice:
    profiles: ["apollo"]
    image: apolloconfig/apollo-configservice:2.1.0
    container_name: lynx-apollo-config
    ports:
      - "8080:8080"   # Apollo config service port
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/ApolloConfigDB?characterEncoding=utf8
      SPRING_DATASOURCE_USERNAME: lynx
      SPRING_DATASOURCE_PASSWORD: lynx123456
      EUREKA_INSTANCE_IP_ADDRESS: apollo-configservice
    depends_on:
      mysql:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network
    restart: on-failure

  # Apollo Admin Service
  # Note: If image pull fails, try configuring Docker registry mirror or use: docker pull apolloconfig/apollo-adminservice:2.1.0
  apollo-adminservice:
    profiles: ["apollo"]
    image: apolloconfig/apollo-adminservice:2.1.0
    container_name: lynx-apollo-admin
    ports:
      - "8090:8090"   # Apollo admin service port
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/ApolloConfigDB?characterEncoding=utf8
      SPRING_DATASOURCE_USERNAME: lynx
      SPRING_DATASOURCE_PASSWORD: lynx123456
      EUREKA_SERVICE_URL: http://apollo-configservice:8080/eureka/
      EUREKA_INSTANCE_IP_ADDRESS: apollo-adminservice
    depends_on:
      mysql:
        condition: service_healthy
      apollo-configservice:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8090/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network
    restart: on-failure

  # Apollo Portal
  # Note: If image pull fails, try configuring Docker registry mirror or use: docker pull apolloconfig/apollo-portal:2.1.0
  apollo-portal:
    profiles: ["apollo"]
    image: apolloconfig/apollo-portal:2.1.0
    container_name: lynx-apollo-portal
    ports:
      - "8070:8070"   # Apollo portal port
    environment:
      SPRING_DATASOURCE_URL: jdbc:mysql://mysql:3306/ApolloPortalDB?characterEncoding=utf8
      SPRING_DATASOURCE_USERNAME: lynx
      SPRING_DATASOURCE_PASSWORD: lynx123456
      APOLLO_PORTAL_ENVS: dev
      DEV_META: http://apollo-configservice:8080
      EUREKA_INSTANCE_IP_ADDRESS: apollo-portal
    depends_on:
      mysql:
        condition: service_healthy
      apollo-configservice:
        condition: service_healthy
      apollo-adminservice:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8070/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network
    restart: on-failure

  # OpenTelemetry Collector (for tracer plugin)
  otel-collector:
    image: otel/opentelemetry-collector:latest
    container_name: lynx-otel-collector
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "55679:55679" # zpages extension
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml
    command: ["--config=/etc/otel-collector-config.yaml"]
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:55679"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network

  # Jaeger (for distributed tracing visualization)
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: lynx-jaeger
    ports:
      - "16686:16686"   # Jaeger UI
      - "14268:14268"   # Jaeger collector HTTP
      - "14250:14250"   # Jaeger collector gRPC
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686/"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - lynx-network


volumes:
  redis-data:
  mysql-data:
  postgres-data:
  es-data:
  mongo-data:
  rabbitmq-data:
  polaris-data:
  nacos-data:
  nacos-logs:
  etcd-data:
  pulsar-data:
  seata-data:
  mssql-data:
  apollo-data:

networks:
  lynx-network:
    driver: bridge